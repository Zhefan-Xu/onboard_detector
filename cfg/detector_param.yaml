localization_mode: 0 # 0: pose (default) 1: odom

# depth_image_topic: /camera/depth/image_raw
color_image_topic: /camera/color/image_raw
lidar_pointcloud_topic: /livox_pcl0
# lidar_pointcloud_topic: /cloud_registered
# pose_topic: /CERLAB/quadcopter/pose
odom_topic: /CERLAB/quadcopter/odom

depth_image_topic: /camera/depth/image_rect_raw
# aligned_depth_image_topic: /camera/aligned_depth_to_color/image_raw
pose_topic: /mavros/local_position/pose
# odom_topic: /vins_estimator/imu_propagate

# Camera Parameters
# depth_intrinsics: [386.22674560546875, 386.22674560546875, 317.3930969238281, 239.78431701660156] # fx,  fy, cx, cy realsense
depth_intrinsics: [554.254691191187, 554.254691191187, 320.5, 240.5] # fx,  fy, cx, cy simulation
color_intrinsics: [554.254691191187, 554.254691191187, 320.5, 240.5] # fx,  fy, cx, cy simulation
# color_intrinsics: [608.08740234375, 608.08740234375, 317.48284912109375, 234.11557006835938] # intel realsense
# depth_scale_factor: 1000 # 1000 for Intel Realsense Camera
depth_scale_factor: 10 # simulation
depth_min_value: 0.5
depth_max_value: 5.0
depth_filter_margin: 10 # filter
depth_skip_pixel: 2  # filter
image_cols: 640
image_rows: 480
body_to_camera: [0.0,  0.0,  1.0,  0.09,
                -1.0,  0.0,  0.0,  0.0 ,   
                 0.0, -1.0,  0.0,  0.095,
                 0.0,  0.0,  0.0,  1.0]
body_to_camera_color: [0.0,  0.0,  1.0,  0.09,
                -1.0,  0.0,  0.0,  0.0 ,   
                 0.0, -1.0,  0.0,  0.095,
                 0.0,  0.0,  0.0,  1.0]
body_to_lidar:  [1.0,  0.0,  0.0,  0.0,
                 0.0,  1.0,  0.0,  0.0 ,   
                 0.0,  0.0,  1.0,  0.15,
                 0.0,  0.0,  0.0,  1.0]




# Raycasting (max depth)
raycast_max_length: 5.0

# time difference
time_difference: 0.033

# sensor data processing
voxel_occupied_thresh: 5 # min num of points for a voxel to be occupied in voxel filter

# dbscan
ground_height: 0.1 # height of ground to remove ground points
roof_height: 2.0 # relative height of roof to remove roof points
dbscan_min_points_cluster: 10 # 20: 4.0m range; 30: 3.5m range 40: 3.0m range
dbscan_search_range_epsilon: 0.1 # searching range radius

# lidar dbscan
lidar_DBSCAN_min_points: 15
lidar_DBSCAN_epsilon: 0.1
downsample_threshold: 3000 # threshold for downsampling


# bounding box filtering
filtering_BBox_IOU_threshold: 0.05
yolo_overwrite_distance: 10

# tracking and data association
history_size: 100 # size of tracking history. history[0] is current detection
prediction_size: 20 # size of prediction
similarity_threshold: 0.9 # similiary threshold for data association matching comparison
retrack_similarity_threshold: 0.5 # similiary threshold for retracking
fix_size_history_threshold: 10 # History threshold (num of frames) to fix box size
fix_size_dimension_threshold: 0.4 # dimension threshold (size of proportional) to fix box size

e_p: 0.25
e_q_pos: 0.01
e_q_vel: 0.05
e_q_acc: 0.05
e_r_pos: 0.04
e_r_vel: 0.3
e_r_acc: 0.6

kalman_filter_averaging_frames: 10

# classification
frame_skip: 5 # num of frames skiped when comparing 2 point clouds
dynamic_velocity_threshold: 0.10
dynamic_voting_threshold: 0.6
maximum_skip_ratio: 0.5 # the upper limit of points that are skipped(out of previous FOV) to be classfified as dynamic
frames_force_dynamic: 5 # Range of searching dynamic obstacles in box history
frames_force_dynamic_check_range: 30 # threshold for forcing dynamic obstacles
dynamic_consistency_threshold: 5 # obstacles being voted as dynamic for continuous k frames are eligible to be classified as dynamic

# constrain size
constrain_size: false
target_object_size: [0.5, 0.5, 1.5]
target_object_size_threshold: [2.0, 2.0, 2.0] # filter out objects that are too large
